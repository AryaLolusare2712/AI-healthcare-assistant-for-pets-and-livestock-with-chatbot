{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d33271-a338-4b93-aa43-ae98321cdbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryal\\AppData\\Local\\Temp\\ipykernel_27296\\940048428.py:174: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chat = gr.Chatbot(label=\"üí¨ Conversation\", height=420)\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import uuid\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "# --- external model lib ---\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- setup logging ---\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"pawsence\")\n",
    "\n",
    "# --- load config ---\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"Set GOOGLE_API_KEY in env or directly in notebook\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "MODEL_NAME = \"gemini-1.5-flash\"\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "# --- in-memory session store (for demo only) ---\n",
    "SESSIONS = {}\n",
    "\n",
    "DISCLAIMER = (\n",
    "    \"‚ö† Disclaimer: I am an AI assistant for preliminary animal health guidance. \"\n",
    "    \"This is NOT a substitute for a veterinarian. Always consult a vet for diagnosis or treatment.\"\n",
    ")\n",
    "\n",
    "# --- helpers ---\n",
    "def safe_text_from_response(response):\n",
    "    # defensive: different SDK shapes\n",
    "    if response is None:\n",
    "        return \"\"\n",
    "    if hasattr(response, \"text\"):\n",
    "        return response.text or \"\"\n",
    "    if getattr(response, \"candidates\", None):\n",
    "        try:\n",
    "            return response.candidates[0].content\n",
    "        except Exception:\n",
    "            return str(response)\n",
    "    return str(response)\n",
    "\n",
    "def image_to_jpeg_bytes(pil_img: Image.Image, max_size=(1600,1600)):\n",
    "    # validate & resize to reasonable size, return jpeg bytes\n",
    "    if pil_img.mode not in (\"RGB\", \"RGBA\"):\n",
    "        pil_img = pil_img.convert(\"RGB\")\n",
    "    pil_img.thumbnail(max_size, Image.LANCZOS)\n",
    "    buf = io.BytesIO()\n",
    "    pil_img.save(buf, format=\"JPEG\", quality=85)\n",
    "    buf.seek(0)\n",
    "    return buf.read()\n",
    "\n",
    "# improved urgent detection: whole-word patterns (case-insensitive)\n",
    "URGENT_PATTERNS = [\n",
    "    r\"\\bnot breathing\\b\",\n",
    "    r\"\\bno breath\\b\",\n",
    "    r\"\\bseizure\\b\",\n",
    "    r\"\\bconvulsion\\b\",\n",
    "    r\"\\bcollapse(ed|ing)?\\b\",\n",
    "    r\"\\bbleeding (heavily|a lot|profusely)\\b\",\n",
    "    r\"\\bcannot stand\\b\",\n",
    "    r\"\\bwon't stand\\b\",\n",
    "    r\"\\bsudden death\\b\",\n",
    "]\n",
    "\n",
    "def is_urgent(text: str) -> bool:\n",
    "    text = (text or \"\").lower()\n",
    "    return any(re.search(p, text) for p in URGENT_PATTERNS)\n",
    "\n",
    "# API call with defensive handling\n",
    "def call_gemini(conversation_messages, image_bytes=None):\n",
    "    # Build inputs for Gemini: structured list, last user prompt is the focus\n",
    "    inputs = []\n",
    "    # convert structured history to single-string items (Gemini flexible)\n",
    "    for m in conversation_messages:\n",
    "        role = m.get(\"role\", \"user\")\n",
    "        content = m.get(\"content\", \"\")\n",
    "        inputs.append(f\"[{role.upper()}] {content}\")\n",
    "\n",
    "    if image_bytes:\n",
    "        inputs.append({\"mime_type\": \"image/jpeg\", \"data\": image_bytes})\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            inputs,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.2,\n",
    "                \"top_p\": 0.95,\n",
    "                \"max_output_tokens\": 512,\n",
    "            }\n",
    "        )\n",
    "        return safe_text_from_response(response)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Gemini call failed\")\n",
    "        return f\"‚ö† Error: failed to call model: {e}\"\n",
    "\n",
    "# triage + memory\n",
    "def triage_and_generate(session_id, user_text, pil_img, species):\n",
    "    session = SESSIONS.setdefault(session_id, {\"history\": []})\n",
    "    timestamp = datetime.utcnow().isoformat()\n",
    "    user_entry = {\"role\": \"user\", \"content\": f\"Species: {species}. {user_text}\", \"time\": timestamp}\n",
    "    session[\"history\"].append(user_entry)\n",
    "\n",
    "    urgent_flag = is_urgent(user_text)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that provides safe, evidence-based veterinary triage. \"\n",
    "        \"Keep replies concise. If key facts are missing (species, age, vaccination, trauma), ask one follow-up question. \"\n",
    "        \"If the condition appears medically urgent, respond with 'ESCALATE' and recommend immediate veterinary care.\"\n",
    "    )\n",
    "\n",
    "    # Build conversation: system prompt + disclaimer + recent history (limit to last N entries)\n",
    "    recent = session[\"history\"][-12:]  # keep last 12 turns to limit size\n",
    "    conv = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"system\", \"content\": DISCLAIMER}]\n",
    "    conv.extend(recent)\n",
    "\n",
    "    img_bytes = None\n",
    "    if pil_img:\n",
    "        try:\n",
    "            img_bytes = image_to_jpeg_bytes(pil_img)\n",
    "            conv.append({\"role\": \"user\", \"content\": \"Image attached: please describe visible signs and urgency.\"})\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Image processing failed\")\n",
    "            session[\"history\"].append({\"role\": \"assistant\", \"content\": f\"‚ö† Error processing image: {e}\"})\n",
    "            return format_chat(session[\"history\"]), \"\"\n",
    "\n",
    "    reply_text = call_gemini(conv, image_bytes=img_bytes)\n",
    "    if urgent_flag:\n",
    "        reply_text = \"‚ö† ESCALATE: This appears urgent. \" + reply_text\n",
    "\n",
    "    session[\"history\"].append({\"role\": \"assistant\", \"content\": reply_text, \"time\": datetime.utcnow().isoformat()})\n",
    "    return format_chat(session[\"history\"]), reply_text\n",
    "\n",
    "def format_chat(history):\n",
    "    # Convert stored history into list of (user, assistant) pairs for gr.Chatbot\n",
    "    # We'll iterate and collect messages in order; whenever 'user' add a tuple; when 'assistant' follow.\n",
    "    chat_display = []\n",
    "    for entry in history:\n",
    "        role = entry.get(\"role\", \"user\")\n",
    "        content = entry.get(\"content\", \"\")\n",
    "        if role == \"user\":\n",
    "            chat_display.append((\"You\", content))\n",
    "        elif role == \"assistant\":\n",
    "            chat_display.append((\"PawSence\", content))\n",
    "        else:\n",
    "            # system or others ‚Äî show as assistant note\n",
    "            chat_display.append((\"System\", content))\n",
    "    return chat_display\n",
    "\n",
    "# --- Gradio UI ---\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            <div style=\"text-align: center;\">\n",
    "                <h1>üêæ PawSence</h1>\n",
    "                <h3 style=\"color: #555;\">Your AI Vet Companion ‚Äî Caring for Pets, Powered by AI</h3>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            chat = gr.Chatbot(label=\"üí¨ Conversation\", height=420)\n",
    "            with gr.Row():\n",
    "                txt = gr.Textbox(placeholder=\"‚úç Describe symptoms or ask a question...\", lines=2)\n",
    "                send = gr.Button(\"üöÄ Send\", variant=\"primary\")\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### ‚öô Case Details\")\n",
    "            species = gr.Dropdown(choices=[\"Dog\",\"Cat\",\"Horse\",\"Cow\",\"Goat\",\"Sheep\",\"Pig\",\"Other\"],\n",
    "                                  label=\"Species\", value=\"Dog\")\n",
    "            # return PIL Image to process safely\n",
    "            img = gr.Image(type=\"pil\", label=\"üì∑ Upload Image (optional)\", height=200)\n",
    "            # session id: default new uuid per user; for demo we expose a button to new session\n",
    "            session_id_state = gr.State(str(uuid.uuid4()))\n",
    "            clear_btn = gr.Button(\"üÜï Start New Session\", variant=\"secondary\")\n",
    "\n",
    "    # events\n",
    "    def user_submit(user_text, pil_img, sess_state, species_val):\n",
    "        # create new session id if state is empty\n",
    "        if not sess_state:\n",
    "            sess_state = str(uuid.uuid4())\n",
    "\n",
    "        messages, raw_reply = triage_and_generate(sess_state, user_text, pil_img, species_val)\n",
    "        # Clear input textbox and image after send (return values for outputs)\n",
    "        return messages, \"\", None, sess_state\n",
    "\n",
    "    def reset_session():\n",
    "        new_id = str(uuid.uuid4())\n",
    "        SESSIONS[new_id] = {\"history\": []}\n",
    "        return [], \"\", None, new_id\n",
    "\n",
    "    send.click(user_submit, inputs=[txt, img, session_id_state, species],\n",
    "               outputs=[chat, txt, img, session_id_state])\n",
    "    clear_btn.click(reset_session, outputs=[chat, txt, img, session_id_state])\n",
    "\n",
    "# For notebooks or simple local run:\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=False, inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dea403-e4c2-4f09-9447-4002a6e33095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
