{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505732d-8911-4d0b-af46-0de7e05d123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, io, uuid, logging, re, threading, time, smtplib\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "import speech_recognition as sr\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760bb64-2dba-4769-82fe-7724574e3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"pawsense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2665d78e-188a-4879-acb0-574fe4fbc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"Set GOOGLE_API_KEY in env\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL_NAME = \"gemini-1.5-flash\"\n",
    "model = genai.GenerativeModel(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2374d2-0a2f-44e5-bc82-db91fbf6e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email Config\n",
    "EMAIL_HOST = os.getenv(\"EMAIL_HOST\")\n",
    "EMAIL_PORT = int(os.getenv(\"EMAIL_PORT\", 587))\n",
    "EMAIL_USER = os.getenv(\"EMAIL_USER\")\n",
    "EMAIL_PASS = os.getenv(\"EMAIL_PASS\")\n",
    "EMAIL_SENDER = os.getenv(\"EMAIL_SENDER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cd2e7-b2d0-4c75-b3a6-fe32eb919a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-memory session store\n",
    "SESSIONS = {}\n",
    "\n",
    "DISCLAIMER = (\n",
    "    \"‚ö† Disclaimer: I am an AI assistant for preliminary animal health guidance. \"\n",
    "    \"This is NOT a substitute for a veterinarian. Always consult a vet for diagnosis or treatment.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5e785-65a1-4b20-bd1b-95f52a62f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera monitoring\n",
    "camera_alert_flag = False\n",
    "receiver_email_global = None\n",
    "\n",
    "def monitor_camera(cam_index=0, check_interval=2, diff_threshold=0.6):\n",
    "    global camera_alert_flag\n",
    "    cap = cv2.VideoCapture(cam_index)\n",
    "    if not cap.isOpened():\n",
    "        logger.error(\"Camera not found!\")\n",
    "        camera_alert_flag = True\n",
    "        send_email_alert(\"‚ö† Camera not found!\")\n",
    "        return\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        logger.error(\"Unable to read from camera\")\n",
    "        camera_alert_flag = True\n",
    "        send_email_alert(\"‚ö† Unable to read from camera\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        time.sleep(check_interval)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            logger.error(\"‚ö† Camera disconnected!\")\n",
    "            camera_alert_flag = True\n",
    "            send_email_alert(\"‚ö† Camera disconnected!\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        diff = cv2.absdiff(prev_gray, gray)\n",
    "        change_ratio = np.count_nonzero(diff) / diff.size\n",
    "\n",
    "        if change_ratio > diff_threshold:\n",
    "            logger.warning(\"‚ö† Camera direction changed significantly!\")\n",
    "            camera_alert_flag = True\n",
    "            send_email_alert(\"‚ö† Camera direction changed significantly!\")\n",
    "\n",
    "        prev_gray = gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201b563-2062-4c0d-af18-f81d75d08a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email Helper\n",
    "def send_email_alert(message):\n",
    "    global receiver_email_global\n",
    "    if not receiver_email_global:\n",
    "        logger.warning(\"‚ö† No receiver email set, skipping email.\")\n",
    "        return\n",
    "    try:\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = EMAIL_SENDER\n",
    "        msg['To'] = receiver_email_global\n",
    "        msg['Subject'] = \"üêæ PawSense Alert\"\n",
    "        msg.attach(MIMEText(message, \"plain\"))\n",
    "        with smtplib.SMTP(EMAIL_HOST, EMAIL_PORT) as server:\n",
    "            server.starttls()\n",
    "            server.login(EMAIL_USER, EMAIL_PASS)\n",
    "            server.sendmail(EMAIL_SENDER, receiver_email_global, msg.as_string())\n",
    "        logger.info(f\"‚úÖ Email alert sent to {receiver_email_global}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to send email: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607fbe9-827f-4c30-8fe3-262baf43d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_text_from_response(response):\n",
    "    if response is None:\n",
    "        return \"\"\n",
    "    if hasattr(response, \"text\"):\n",
    "        return response.text or \"\"\n",
    "    if getattr(response, \"candidates\", None):\n",
    "        try:\n",
    "            return response.candidates[0].content\n",
    "        except Exception:\n",
    "            return str(response)\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b24f80-8b6c-47bc-9d20-503e1c83430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_jpeg_bytes(pil_img: Image.Image, max_size=(1600,1600)):\n",
    "    if pil_img.mode not in (\"RGB\", \"RGBA\"):\n",
    "        pil_img = pil_img.convert(\"RGB\")\n",
    "    pil_img.thumbnail(max_size, Image.LANCZOS)\n",
    "    buf = io.BytesIO()\n",
    "    pil_img.save(buf, format=\"JPEG\", quality=85)\n",
    "    buf.seek(0)\n",
    "    return buf.read()\n",
    "\n",
    "URGENT_PATTERNS = [\n",
    "    r\"\\bnot breathing\\b\", r\"\\bno breath\\b\", r\"\\bseizure\\b\", r\"\\bconvulsion\\b\",\n",
    "    r\"\\bcollapse(ed|ing)?\\b\", r\"\\bbleeding (heavily|a lot|profusely)\\b\",\n",
    "    r\"\\bcannot stand\\b\", r\"\\bwon't stand\\b\", r\"\\bsudden death\\b\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88fa23-87cb-44c2-88ff-59dc94cf9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_urgent(text: str) -> bool:\n",
    "    text = (text or \"\").lower()\n",
    "    return any(re.search(p, text) for p in URGENT_PATTERNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f674073-b7b4-40a3-a6ab-132f0f68be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(conversation_messages, image_bytes=None):\n",
    "    inputs = []\n",
    "    for m in conversation_messages:\n",
    "        role = m.get(\"role\", \"user\")\n",
    "        content = m.get(\"content\", \"\")\n",
    "        inputs.append(f\"[{role.upper()}] {content}\")\n",
    "    if image_bytes:\n",
    "        inputs.append({\"mime_type\": \"image/jpeg\", \"data\": image_bytes})\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            inputs,\n",
    "            generation_config={\"temperature\": 0.2, \"top_p\": 0.95, \"max_output_tokens\": 512}\n",
    "        )\n",
    "        return safe_text_from_response(response)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Gemini call failed\")\n",
    "        return f\"‚ö† Error: failed to call model: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61afb48-fc5b-4a46-b402-333f896d2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS\n",
    "def text_to_audio(text, filename=\"reply.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"en\")\n",
    "    tts.save(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9a2e0-338f-4516-9978-94afb54e7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STT\n",
    "def audio_to_text(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        return r.recognize_google(audio)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Speech recognition failed: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d85365-44db-4ad9-adce-3a13f87838c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Analysis Helper\n",
    "def analyze_video(video_path, species):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return \"‚ö† Unable to process video file.\"\n",
    "    \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sample_rate = max(1, frame_count // 5)\n",
    "    frames = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % sample_rate == 0:\n",
    "            pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            frames.append(pil_img)\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    insights = []\n",
    "    for i, img in enumerate(frames):\n",
    "        img_bytes = image_to_jpeg_bytes(img)\n",
    "        prompt = f\"Analyze visible signs of distress, injury, or abnormal behavior in this {species}. Be concise.\"\n",
    "        response = model.generate_content(\n",
    "            [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"system\", \"content\": DISCLAIMER}],\n",
    "            image=img_bytes,\n",
    "            generation_config={\"temperature\": 0.2, \"top_p\": 0.9, \"max_output_tokens\": 300}\n",
    "        )\n",
    "        insights.append(safe_text_from_response(response))\n",
    "\n",
    "    summary_prompt = (\n",
    "        f\"Summarize these frame-based findings into a concise veterinary observation for a {species}: \"\n",
    "        + \" \".join(insights)\n",
    "    )\n",
    "    final_response = call_gemini([{\"role\": \"user\", \"content\": summary_prompt}])\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024196b3-10a1-478c-894a-f0c0021628bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triage Logic\n",
    "def triage_and_generate(session_id, user_text, pil_img, species):\n",
    "    session = SESSIONS.setdefault(session_id, {\"history\": []})\n",
    "    timestamp = datetime.utcnow().isoformat()\n",
    "    session[\"history\"].append({\"role\": \"user\", \"content\": f\"Species: {species}. {user_text}\", \"time\": timestamp})\n",
    "\n",
    "    urgent_flag = is_urgent(user_text)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that provides safe, evidence-based veterinary triage. \"\n",
    "        \"Keep replies concise. If key facts are missing (species, age, vaccination, trauma), ask one follow-up. \"\n",
    "        \"If urgent, respond with 'ESCALATE' and recommend immediate veterinary care.\"\n",
    "    )\n",
    "\n",
    "    conv = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"system\", \"content\": DISCLAIMER}]\n",
    "    conv.extend(session[\"history\"][-12:])\n",
    "\n",
    "    img_bytes = None\n",
    "    if pil_img:\n",
    "        try:\n",
    "            img_bytes = image_to_jpeg_bytes(pil_img)\n",
    "            conv.append({\"role\": \"user\", \"content\": \"Image attached: please describe visible signs and urgency.\"})\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Image processing failed\")\n",
    "            session[\"history\"].append({\"role\": \"assistant\", \"content\": f\"‚ö† Error processing image: {e}\"})\n",
    "            return format_chat(session[\"history\"]), \"\", None\n",
    "\n",
    "    reply_text = call_gemini(conv, image_bytes=img_bytes)\n",
    "    if urgent_flag:\n",
    "        reply_text = \"‚ö† ESCALATE: This appears urgent. \" + reply_text\n",
    "        send_email_alert(f\"Urgent case detected!\\n\\n{user_text}\")\n",
    "\n",
    "    session[\"history\"].append({\"role\": \"assistant\", \"content\": reply_text, \"time\": datetime.utcnow().isoformat()})\n",
    "    audio_file = text_to_audio(reply_text)\n",
    "    return format_chat(session[\"history\"]), reply_text, audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bb177-0460-48b5-9630-e6ab49f10c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Chat\n",
    "def format_chat(history):\n",
    "    chat_display = []\n",
    "    last_user = None\n",
    "    for entry in history:\n",
    "        role = entry.get(\"role\", \"user\")\n",
    "        content = entry.get(\"content\", \"\")\n",
    "        if role == \"user\":\n",
    "            last_user = content\n",
    "        elif role == \"assistant\":\n",
    "            chat_display.append((last_user or \"\", content))\n",
    "            last_user = None\n",
    "        else:\n",
    "            chat_display.append((\"System\", content))\n",
    "    return chat_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855d096-cc38-440a-a5a6-ae6de94599d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"\"\"\n",
    "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
    "            <h1 style=\"font-size: 2.2em; color: #4a5568;\">üêæ PawSence</h1>\n",
    "            <p style=\"font-size: 1.1em; color: #6b7280;\">\n",
    "                Your AI Vet Companion ‚Äî Caring for Pets, Powered by AI\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=2):\n",
    "            chat = gr.Chatbot(label=\"üí¨ Conversation\", height=460)\n",
    "            with gr.Row():\n",
    "                txt = gr.Textbox(placeholder=\"‚úç Describe symptoms or ask a question...\", lines=2, label=\"Type Symptoms\")\n",
    "                send = gr.Button(\"üöÄ Send\", variant=\"primary\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### ‚öô Case Details\")\n",
    "            mode_toggle = gr.Radio(choices=[\"Text Mode\", \"Voice Mode\"], value=\"Text Mode\", label=\"Interaction Mode\")\n",
    "            species = gr.Dropdown(choices=[\"Dog\",\"Cat\",\"Horse\",\"Cow\",\"Goat\",\"Sheep\",\"Pig\",\"Other\"], label=\"Species\", value=\"Select\")\n",
    "            email_input = gr.Textbox(label=\"üìß Receiver Email\", placeholder=\"Enter your email to get alerts\")\n",
    "            img = gr.Image(type=\"pil\", label=\"üì∑ Upload Image (optional)\", height=180)\n",
    "            video_input = gr.Video(label=\"üéû Upload Video (optional)\", height=180)\n",
    "            video_btn = gr.Button(\"üìä Analyze Video\", variant=\"secondary\")\n",
    "\n",
    "            with gr.Row():\n",
    "                audio_in = gr.Audio(type=\"filepath\", label=\"üé§ Speak Symptoms\", sources=[\"microphone\"], interactive=True, visible=False)\n",
    "            audio_btn = gr.Button(\"üéô Convert Audio ‚Üí Text\", variant=\"secondary\", visible=False)\n",
    "\n",
    "            clear_btn = gr.Button(\"üÜï Start New Session\", variant=\"secondary\")\n",
    "            alert_box = gr.Textbox(label=\"üì¢ System Alerts\", interactive=False)\n",
    "            session_id_state = gr.State(str(uuid.uuid4()))\n",
    "\n",
    "    # Events\n",
    "    def user_submit(user_text, pil_img, sess_state, species_val, email_val):\n",
    "        global receiver_email_global\n",
    "        if email_val:\n",
    "            receiver_email_global = email_val.strip()\n",
    "        if not sess_state:\n",
    "            sess_state = str(uuid.uuid4())\n",
    "        chat_display, reply_text, audio_file = triage_and_generate(sess_state, user_text, pil_img, species_val)\n",
    "        return chat_display, \"\", None, sess_state\n",
    "\n",
    "    def reset_session():\n",
    "        new_id = str(uuid.uuid4())\n",
    "        SESSIONS[new_id] = {\"history\": []}\n",
    "        return [], \"\", None, new_id\n",
    "\n",
    "    def handle_audio(audio_path, sess_state, species_val):\n",
    "        if not audio_path:\n",
    "            return \"\", sess_state\n",
    "        text = audio_to_text(audio_path)\n",
    "        return text, sess_state\n",
    "\n",
    "    def toggle_mode(mode):\n",
    "        if mode == \"Text Mode\":\n",
    "            return gr.update(visible=True), gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
    "        else:\n",
    "            return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True), gr.update(visible=True)\n",
    "\n",
    "    def handle_video(video_path, species_val):\n",
    "        if not video_path:\n",
    "            return [(\"System\", \"‚ö† No video uploaded.\")]\n",
    "        result = analyze_video(video_path, species_val)\n",
    "        return [(\"üéû Video Analysis Result\", result)]\n",
    "\n",
    "    def check_alerts():\n",
    "        global camera_alert_flag\n",
    "        if camera_alert_flag:\n",
    "            return \"‚ö† ALERT: Camera disconnected or tampered!\"\n",
    "        return \"\"\n",
    "\n",
    "    send.click(user_submit, inputs=[txt, img, session_id_state, species, email_input], outputs=[chat, txt, img, session_id_state])\n",
    "    clear_btn.click(reset_session, outputs=[chat, txt, img, session_id_state])\n",
    "    audio_btn.click(handle_audio, inputs=[audio_in, session_id_state, species], outputs=[txt, session_id_state])\n",
    "    video_btn.click(handle_video, inputs=[video_input, species], outputs=[chat])\n",
    "    mode_toggle.change(toggle_mode, inputs=[mode_toggle], outputs=[txt, send, audio_in, audio_btn])\n",
    "\n",
    "    alert_timer = gr.Timer(value=3000, active=True)\n",
    "    alert_timer.tick(check_alerts, outputs=[alert_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98426f69-af92-43f7-ba89-5629c41dfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start monitoring thread\n",
    "monitor_thread = threading.Thread(target=monitor_camera, daemon=True)\n",
    "monitor_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f8a0f-114a-4090-8a6e-3a454cb70f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch(share=False, inline=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
